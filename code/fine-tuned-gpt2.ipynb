{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from torch.utils.data import random_split\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accounting technicians handle daytoday money a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admin assistants give support to businesses by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arts administrators help organise exhibitions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant immigration officers check that peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>internal and external auditors check organisat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  accounting technicians handle daytoday money a...\n",
       "1  admin assistants give support to businesses by...\n",
       "2  arts administrators help organise exhibitions ...\n",
       "3  assistant immigration officers check that peop...\n",
       "4  internal and external auditors check organisat..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('careers_single.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer with special tokens\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanrodrigues/opt/miniconda3/envs/tensorflow/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset and convert it to a PyTorch dataset\n",
    "text_dataset = TextDataset(tokenizer=tokenizer, file_path=\"careers_single.csv\", block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "train_size = int(0.9 * len(text_dataset))\n",
    "val_size = len(text_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(text_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False, \n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./\", \n",
    "    overwrite_output_dir=True, \n",
    "    num_train_epochs=3, \n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=16,\n",
    "    save_total_limit=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    data_collator=data_collator, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanrodrigues/opt/miniconda3/envs/tensorflow/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7578\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1422\n",
      "  Number of trainable parameters = 124439808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d721b41bc548d3a88bb4653038bc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.3655, 'learning_rate': 1.9859353023909988e-05, 'epoch': 0.02}\n",
      "{'loss': 3.9457, 'learning_rate': 1.9718706047819975e-05, 'epoch': 0.04}\n",
      "{'loss': 3.6474, 'learning_rate': 1.957805907172996e-05, 'epoch': 0.06}\n",
      "{'loss': 3.5178, 'learning_rate': 1.9437412095639944e-05, 'epoch': 0.08}\n",
      "{'loss': 3.399, 'learning_rate': 1.929676511954993e-05, 'epoch': 0.11}\n",
      "{'loss': 3.0913, 'learning_rate': 1.9156118143459917e-05, 'epoch': 0.13}\n",
      "{'loss': 3.0143, 'learning_rate': 1.9015471167369904e-05, 'epoch': 0.15}\n",
      "{'loss': 3.0163, 'learning_rate': 1.8874824191279887e-05, 'epoch': 0.17}\n",
      "{'loss': 2.9691, 'learning_rate': 1.8734177215189874e-05, 'epoch': 0.19}\n",
      "{'loss': 2.739, 'learning_rate': 1.859353023909986e-05, 'epoch': 0.21}\n",
      "{'loss': 2.7906, 'learning_rate': 1.8452883263009847e-05, 'epoch': 0.23}\n",
      "{'loss': 2.5987, 'learning_rate': 1.8312236286919833e-05, 'epoch': 0.25}\n",
      "{'loss': 2.5854, 'learning_rate': 1.8171589310829816e-05, 'epoch': 0.27}\n",
      "{'loss': 2.5603, 'learning_rate': 1.8030942334739806e-05, 'epoch': 0.3}\n",
      "{'loss': 2.5975, 'learning_rate': 1.789029535864979e-05, 'epoch': 0.32}\n",
      "{'loss': 2.6328, 'learning_rate': 1.7749648382559776e-05, 'epoch': 0.34}\n",
      "{'loss': 2.6102, 'learning_rate': 1.7609001406469762e-05, 'epoch': 0.36}\n",
      "{'loss': 2.5128, 'learning_rate': 1.746835443037975e-05, 'epoch': 0.38}\n",
      "{'loss': 2.5378, 'learning_rate': 1.7327707454289736e-05, 'epoch': 0.4}\n",
      "{'loss': 2.3808, 'learning_rate': 1.718706047819972e-05, 'epoch': 0.42}\n",
      "{'loss': 2.4784, 'learning_rate': 1.7046413502109705e-05, 'epoch': 0.44}\n",
      "{'loss': 2.5127, 'learning_rate': 1.6905766526019692e-05, 'epoch': 0.46}\n",
      "{'loss': 2.4796, 'learning_rate': 1.6765119549929678e-05, 'epoch': 0.49}\n",
      "{'loss': 2.4248, 'learning_rate': 1.662447257383966e-05, 'epoch': 0.51}\n",
      "{'loss': 2.3828, 'learning_rate': 1.648382559774965e-05, 'epoch': 0.53}\n",
      "{'loss': 2.4674, 'learning_rate': 1.6343178621659638e-05, 'epoch': 0.55}\n",
      "{'loss': 2.3052, 'learning_rate': 1.620253164556962e-05, 'epoch': 0.57}\n",
      "{'loss': 2.3438, 'learning_rate': 1.6061884669479608e-05, 'epoch': 0.59}\n",
      "{'loss': 2.1918, 'learning_rate': 1.5921237693389594e-05, 'epoch': 0.61}\n",
      "{'loss': 2.2396, 'learning_rate': 1.578059071729958e-05, 'epoch': 0.63}\n",
      "{'loss': 2.425, 'learning_rate': 1.5639943741209564e-05, 'epoch': 0.65}\n",
      "{'loss': 2.2565, 'learning_rate': 1.549929676511955e-05, 'epoch': 0.68}\n",
      "{'loss': 2.2531, 'learning_rate': 1.5358649789029537e-05, 'epoch': 0.7}\n",
      "{'loss': 2.224, 'learning_rate': 1.5218002812939523e-05, 'epoch': 0.72}\n",
      "{'loss': 2.3024, 'learning_rate': 1.507735583684951e-05, 'epoch': 0.74}\n",
      "{'loss': 2.2118, 'learning_rate': 1.4936708860759495e-05, 'epoch': 0.76}\n",
      "{'loss': 2.1407, 'learning_rate': 1.4796061884669481e-05, 'epoch': 0.78}\n",
      "{'loss': 2.2015, 'learning_rate': 1.4655414908579466e-05, 'epoch': 0.8}\n",
      "{'loss': 2.1638, 'learning_rate': 1.4514767932489453e-05, 'epoch': 0.82}\n",
      "{'loss': 2.2682, 'learning_rate': 1.4374120956399437e-05, 'epoch': 0.84}\n",
      "{'loss': 2.1947, 'learning_rate': 1.4233473980309424e-05, 'epoch': 0.86}\n",
      "{'loss': 2.2206, 'learning_rate': 1.4092827004219412e-05, 'epoch': 0.89}\n",
      "{'loss': 2.2457, 'learning_rate': 1.3952180028129397e-05, 'epoch': 0.91}\n",
      "{'loss': 2.1212, 'learning_rate': 1.3811533052039384e-05, 'epoch': 0.93}\n",
      "{'loss': 2.1111, 'learning_rate': 1.3670886075949368e-05, 'epoch': 0.95}\n",
      "{'loss': 2.1783, 'learning_rate': 1.3530239099859355e-05, 'epoch': 0.97}\n",
      "{'loss': 2.009, 'learning_rate': 1.338959212376934e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 842\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35992b0517da46b1bb9d53a7e6b0fdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9909794330596924, 'eval_runtime': 102.5856, 'eval_samples_per_second': 8.208, 'eval_steps_per_second': 0.517, 'epoch': 1.0}\n",
      "{'loss': 2.1445, 'learning_rate': 1.3248945147679326e-05, 'epoch': 1.01}\n",
      "{'loss': 2.0676, 'learning_rate': 1.3108298171589311e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-500\n",
      "Configuration saved in ./checkpoint-500/config.json\n",
      "Configuration saved in ./checkpoint-500/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0182, 'learning_rate': 1.2967651195499298e-05, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./checkpoint-500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.147, 'learning_rate': 1.2827004219409284e-05, 'epoch': 1.08}\n",
      "{'loss': 2.1259, 'learning_rate': 1.2686357243319269e-05, 'epoch': 1.1}\n",
      "{'loss': 2.1352, 'learning_rate': 1.2545710267229257e-05, 'epoch': 1.12}\n",
      "{'loss': 2.1779, 'learning_rate': 1.240506329113924e-05, 'epoch': 1.14}\n",
      "{'loss': 2.1596, 'learning_rate': 1.2264416315049229e-05, 'epoch': 1.16}\n",
      "{'loss': 2.0971, 'learning_rate': 1.2123769338959213e-05, 'epoch': 1.18}\n",
      "{'loss': 2.0266, 'learning_rate': 1.19831223628692e-05, 'epoch': 1.2}\n",
      "{'loss': 2.0923, 'learning_rate': 1.1842475386779185e-05, 'epoch': 1.22}\n",
      "{'loss': 2.0299, 'learning_rate': 1.1701828410689171e-05, 'epoch': 1.24}\n",
      "{'loss': 2.1248, 'learning_rate': 1.1561181434599158e-05, 'epoch': 1.27}\n",
      "{'loss': 2.0295, 'learning_rate': 1.1420534458509143e-05, 'epoch': 1.29}\n",
      "{'loss': 1.9701, 'learning_rate': 1.127988748241913e-05, 'epoch': 1.31}\n",
      "{'loss': 1.9859, 'learning_rate': 1.1139240506329114e-05, 'epoch': 1.33}\n",
      "{'loss': 2.1802, 'learning_rate': 1.09985935302391e-05, 'epoch': 1.35}\n",
      "{'loss': 2.0165, 'learning_rate': 1.0857946554149085e-05, 'epoch': 1.37}\n",
      "{'loss': 2.0181, 'learning_rate': 1.0717299578059072e-05, 'epoch': 1.39}\n",
      "{'loss': 2.0647, 'learning_rate': 1.057665260196906e-05, 'epoch': 1.41}\n",
      "{'loss': 2.0425, 'learning_rate': 1.0436005625879045e-05, 'epoch': 1.43}\n",
      "{'loss': 1.9413, 'learning_rate': 1.0295358649789031e-05, 'epoch': 1.46}\n",
      "{'loss': 2.0521, 'learning_rate': 1.0154711673699016e-05, 'epoch': 1.48}\n",
      "{'loss': 1.9686, 'learning_rate': 1.0014064697609003e-05, 'epoch': 1.5}\n",
      "{'loss': 1.9834, 'learning_rate': 9.87341772151899e-06, 'epoch': 1.52}\n",
      "{'loss': 1.9757, 'learning_rate': 9.732770745428974e-06, 'epoch': 1.54}\n",
      "{'loss': 2.0456, 'learning_rate': 9.59212376933896e-06, 'epoch': 1.56}\n",
      "{'loss': 2.0711, 'learning_rate': 9.451476793248946e-06, 'epoch': 1.58}\n",
      "{'loss': 1.9821, 'learning_rate': 9.310829817158932e-06, 'epoch': 1.6}\n",
      "{'loss': 2.0122, 'learning_rate': 9.170182841068917e-06, 'epoch': 1.62}\n",
      "{'loss': 2.0057, 'learning_rate': 9.029535864978903e-06, 'epoch': 1.65}\n",
      "{'loss': 1.9711, 'learning_rate': 8.888888888888888e-06, 'epoch': 1.67}\n",
      "{'loss': 1.9443, 'learning_rate': 8.748241912798877e-06, 'epoch': 1.69}\n",
      "{'loss': 2.0208, 'learning_rate': 8.607594936708861e-06, 'epoch': 1.71}\n",
      "{'loss': 2.0505, 'learning_rate': 8.466947960618848e-06, 'epoch': 1.73}\n",
      "{'loss': 1.927, 'learning_rate': 8.326300984528833e-06, 'epoch': 1.75}\n",
      "{'loss': 1.9929, 'learning_rate': 8.18565400843882e-06, 'epoch': 1.77}\n",
      "{'loss': 1.8915, 'learning_rate': 8.045007032348806e-06, 'epoch': 1.79}\n",
      "{'loss': 1.8355, 'learning_rate': 7.90436005625879e-06, 'epoch': 1.81}\n",
      "{'loss': 1.9132, 'learning_rate': 7.763713080168777e-06, 'epoch': 1.84}\n",
      "{'loss': 2.0562, 'learning_rate': 7.623066104078764e-06, 'epoch': 1.86}\n",
      "{'loss': 1.9657, 'learning_rate': 7.482419127988749e-06, 'epoch': 1.88}\n",
      "{'loss': 1.9091, 'learning_rate': 7.341772151898735e-06, 'epoch': 1.9}\n",
      "{'loss': 1.8668, 'learning_rate': 7.201125175808721e-06, 'epoch': 1.92}\n",
      "{'loss': 1.9901, 'learning_rate': 7.060478199718706e-06, 'epoch': 1.94}\n",
      "{'loss': 1.9461, 'learning_rate': 6.919831223628692e-06, 'epoch': 1.96}\n",
      "{'loss': 2.0196, 'learning_rate': 6.779184247538679e-06, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 842\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fa674556af48cd8d23c873079248a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8485240936279297, 'eval_runtime': 69.3184, 'eval_samples_per_second': 12.147, 'eval_steps_per_second': 0.765, 'epoch': 2.0}\n",
      "{'loss': 1.8902, 'learning_rate': 6.638537271448664e-06, 'epoch': 2.0}\n",
      "{'loss': 2.039, 'learning_rate': 6.49789029535865e-06, 'epoch': 2.03}\n",
      "{'loss': 1.8949, 'learning_rate': 6.3572433192686365e-06, 'epoch': 2.05}\n",
      "{'loss': 1.839, 'learning_rate': 6.216596343178622e-06, 'epoch': 2.07}\n",
      "{'loss': 1.9508, 'learning_rate': 6.075949367088608e-06, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-1000\n",
      "Configuration saved in ./checkpoint-1000/config.json\n",
      "Configuration saved in ./checkpoint-1000/generation_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8642, 'learning_rate': 5.935302390998594e-06, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9947, 'learning_rate': 5.79465541490858e-06, 'epoch': 2.13}\n",
      "{'loss': 1.8101, 'learning_rate': 5.654008438818566e-06, 'epoch': 2.15}\n",
      "{'loss': 1.9423, 'learning_rate': 5.5133614627285514e-06, 'epoch': 2.17}\n",
      "{'loss': 2.0231, 'learning_rate': 5.372714486638537e-06, 'epoch': 2.19}\n",
      "{'loss': 1.9954, 'learning_rate': 5.2320675105485245e-06, 'epoch': 2.22}\n",
      "{'loss': 1.831, 'learning_rate': 5.09142053445851e-06, 'epoch': 2.24}\n",
      "{'loss': 1.8362, 'learning_rate': 4.950773558368496e-06, 'epoch': 2.26}\n",
      "{'loss': 2.0137, 'learning_rate': 4.8101265822784815e-06, 'epoch': 2.28}\n",
      "{'loss': 1.8717, 'learning_rate': 4.669479606188467e-06, 'epoch': 2.3}\n",
      "{'loss': 2.04, 'learning_rate': 4.528832630098453e-06, 'epoch': 2.32}\n",
      "{'loss': 1.9845, 'learning_rate': 4.3881856540084394e-06, 'epoch': 2.34}\n",
      "{'loss': 1.974, 'learning_rate': 4.247538677918425e-06, 'epoch': 2.36}\n",
      "{'loss': 1.945, 'learning_rate': 4.106891701828411e-06, 'epoch': 2.38}\n",
      "{'loss': 1.8957, 'learning_rate': 3.9662447257383965e-06, 'epoch': 2.41}\n",
      "{'loss': 1.823, 'learning_rate': 3.825597749648383e-06, 'epoch': 2.43}\n",
      "{'loss': 1.8782, 'learning_rate': 3.684950773558369e-06, 'epoch': 2.45}\n",
      "{'loss': 1.7964, 'learning_rate': 3.544303797468355e-06, 'epoch': 2.47}\n",
      "{'loss': 1.8514, 'learning_rate': 3.4036568213783405e-06, 'epoch': 2.49}\n",
      "{'loss': 1.9568, 'learning_rate': 3.263009845288326e-06, 'epoch': 2.51}\n",
      "{'loss': 2.0014, 'learning_rate': 3.1223628691983127e-06, 'epoch': 2.53}\n",
      "{'loss': 2.0108, 'learning_rate': 2.9817158931082984e-06, 'epoch': 2.55}\n",
      "{'loss': 1.8679, 'learning_rate': 2.841068917018284e-06, 'epoch': 2.57}\n",
      "{'loss': 1.843, 'learning_rate': 2.70042194092827e-06, 'epoch': 2.59}\n",
      "{'loss': 2.1034, 'learning_rate': 2.5597749648382563e-06, 'epoch': 2.62}\n",
      "{'loss': 1.8825, 'learning_rate': 2.4191279887482424e-06, 'epoch': 2.64}\n",
      "{'loss': 1.8711, 'learning_rate': 2.278481012658228e-06, 'epoch': 2.66}\n",
      "{'loss': 1.8689, 'learning_rate': 2.137834036568214e-06, 'epoch': 2.68}\n",
      "{'loss': 1.9922, 'learning_rate': 1.9971870604782e-06, 'epoch': 2.7}\n",
      "{'loss': 1.8777, 'learning_rate': 1.856540084388186e-06, 'epoch': 2.72}\n",
      "{'loss': 2.029, 'learning_rate': 1.7158931082981716e-06, 'epoch': 2.74}\n",
      "{'loss': 1.855, 'learning_rate': 1.5752461322081577e-06, 'epoch': 2.76}\n",
      "{'loss': 1.8443, 'learning_rate': 1.4345991561181436e-06, 'epoch': 2.78}\n",
      "{'loss': 1.8716, 'learning_rate': 1.2939521800281295e-06, 'epoch': 2.81}\n",
      "{'loss': 1.9352, 'learning_rate': 1.1533052039381154e-06, 'epoch': 2.83}\n",
      "{'loss': 1.8821, 'learning_rate': 1.0126582278481013e-06, 'epoch': 2.85}\n",
      "{'loss': 1.9037, 'learning_rate': 8.720112517580873e-07, 'epoch': 2.87}\n",
      "{'loss': 1.9598, 'learning_rate': 7.313642756680732e-07, 'epoch': 2.89}\n",
      "{'loss': 1.8668, 'learning_rate': 5.907172995780591e-07, 'epoch': 2.91}\n",
      "{'loss': 1.8499, 'learning_rate': 4.5007032348804504e-07, 'epoch': 2.93}\n",
      "{'loss': 1.9985, 'learning_rate': 3.09423347398031e-07, 'epoch': 2.95}\n",
      "{'loss': 1.97, 'learning_rate': 1.6877637130801689e-07, 'epoch': 2.97}\n",
      "{'loss': 1.8931, 'learning_rate': 2.8129395218002815e-08, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 842\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6b5981bfbe40238eda27950bf3a3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8132768869400024, 'eval_runtime': 69.5561, 'eval_samples_per_second': 12.105, 'eval_steps_per_second': 0.762, 'epoch': 3.0}\n",
      "{'train_runtime': 7967.0373, 'train_samples_per_second': 2.854, 'train_steps_per_second': 0.178, 'train_loss': 2.168512526443739, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1422, training_loss=2.168512526443739, metrics={'train_runtime': 7967.0373, 'train_samples_per_second': 2.854, 'train_steps_per_second': 0.178, 'train_loss': 2.168512526443739, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in fine-tuned-gpt2/tokenizer_config.json\n",
      "Special tokens file saved in fine-tuned-gpt2/special_tokens_map.json\n",
      "Configuration saved in fine-tuned-gpt2/config.json\n",
      "Configuration saved in fine-tuned-gpt2/generation_config.json\n",
      "Model weights saved in fine-tuned-gpt2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "tokenizer.save_pretrained(\"fine-tuned-gpt2\")\n",
    "model.save_pretrained(\"fine-tuned-gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained and fine-tuned gpt2 models\n",
    "pt_model_name = 'gpt2'\n",
    "pt_model = AutoModelForCausalLM.from_pretrained(pt_model_name)\n",
    "pt_tokenizer = AutoTokenizer.from_pretrained(pt_model_name)\n",
    "ft_model_name = 'fine-tuned-gpt2'\n",
    "ft_model = AutoModelForCausalLM.from_pretrained(ft_model_name)\n",
    "ft_tokenizer = AutoTokenizer.from_pretrained(ft_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"My dad applied for the position of kindergarten teacher.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(prompt, tokenizer, model):\n",
    "    #Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    #Generate text\n",
    "    generated_text = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=50,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        top_k=50\n",
    "    )\n",
    "    output_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "    output = output_text.replace(prompt,'')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: My dad applied for the position of kindergarten teacher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained GPT2 output:  I loved my job, and my mom loved her. She was happy and content,\" she said.\n",
      "\n",
      "\"My dad didn't see anything wrong with me. He loved me. He just didn\n",
      "Fine-tuned GPT2 output: \n",
      "youll need to register with the chartered institution of childcare psychologists\n",
      "employers may ask you to go to a nursery and give a preneural induction if you show good verbal language skills\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"My dad applied for the position of kindergarten teacher.\"\n",
    "prompts = [\n",
    "    \"My dad applied for the position of kindergarten teacher.\"\n",
    "]\n",
    "for prompt in prompts:\n",
    "    print(\"Prompt:\", prompt)\n",
    "    pt_output = generate_output(prompt, pt_tokenizer, pt_model)\n",
    "    print(\"Pre-trained GPT2 output:\", pt_output)\n",
    "    ft_output = generate_output(prompt, ft_tokenizer, ft_model)\n",
    "    print(\"Fine-tuned GPT2 output:\", ft_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a4464dfeb09d8bb859ff233b987e5a8086d95f8aa46b6582b0948e817a56f8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
