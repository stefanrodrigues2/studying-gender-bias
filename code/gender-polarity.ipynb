{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model and tokenizer\n",
    "model_path = 'bert-base-uncased'\n",
    "pt_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "pt_model = BertForMaskedLM.from_pretrained(model_path)\n",
    "\n",
    "# Load fine tuned bert model\n",
    "model_path = 'fine-tuned-bert'\n",
    "ft_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "ft_model = BertForMaskedLM.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of gender-related words to compare\n",
    "words = ['man', 'woman', 'he', 'she', 'boy', 'girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings for each word for both models\n",
    "embeddings_pt = {}\n",
    "for word in words:\n",
    "    tokenized_text = pt_tokenizer.tokenize(word)\n",
    "    indexed_tokens = pt_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    with torch.no_grad():\n",
    "        outputs = pt_model(tokens_tensor)\n",
    "        last_hidden_states = outputs[0]\n",
    "    embeddings_pt[word] = np.mean(last_hidden_states.numpy()[0], axis=0)\n",
    "\n",
    "embeddings_ft = {}\n",
    "for word in words:\n",
    "    tokenized_text = ft_tokenizer.tokenize(word)\n",
    "    indexed_tokens = ft_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    with torch.no_grad():\n",
    "        outputs = ft_model(tokens_tensor)\n",
    "        last_hidden_states = outputs[0]\n",
    "    embeddings_ft[word] = np.mean(last_hidden_states.numpy()[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores for Pre trained Bert:\n",
      "man vs. woman: 0.89\n",
      "man vs. he: 0.89\n",
      "man vs. she: 0.82\n",
      "man vs. boy: 0.90\n",
      "man vs. girl: 0.88\n",
      "woman vs. he: 0.87\n",
      "woman vs. she: 0.84\n",
      "woman vs. boy: 0.91\n",
      "woman vs. girl: 0.92\n",
      "he vs. she: 0.91\n",
      "he vs. boy: 0.87\n",
      "he vs. girl: 0.87\n",
      "she vs. boy: 0.85\n",
      "she vs. girl: 0.84\n",
      "boy vs. girl: 0.96\n",
      "Similarity scores for Fine tuned Bert:\n",
      "man vs. woman: 0.94\n",
      "man vs. he: 0.91\n",
      "man vs. she: 0.91\n",
      "man vs. boy: 0.93\n",
      "man vs. girl: 0.93\n",
      "woman vs. he: 0.90\n",
      "woman vs. she: 0.90\n",
      "woman vs. boy: 0.95\n",
      "woman vs. girl: 0.95\n",
      "he vs. she: 0.93\n",
      "he vs. boy: 0.92\n",
      "he vs. girl: 0.90\n",
      "she vs. boy: 0.92\n",
      "she vs. girl: 0.90\n",
      "boy vs. girl: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cosine similarity between pairs of embeddings for both models\n",
    "similarity_scores_pt = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_pt[word1], embeddings_pt[word2]) / (np.linalg.norm(embeddings_pt[word1]) * np.linalg.norm(embeddings_pt[word2]))\n",
    "        similarity_scores_pt[f'{word1} vs. {word2}'] = similarity\n",
    "\n",
    "similarity_scores_ft = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_ft[word1], embeddings_ft[word2]) / (np.linalg.norm(embeddings_ft[word1]) * np.linalg.norm(embeddings_ft[word2]))\n",
    "        similarity_scores_ft[f'{word1} vs. {word2}'] = similarity\n",
    "\n",
    "\n",
    "# Print the similarity scores for both models\n",
    "print(\"Similarity scores for Pre trained Bert:\")\n",
    "for pair, similarity in similarity_scores_pt.items():\n",
    "    print(f'{pair}: {similarity:.2f}')\n",
    "\n",
    "print(\"Similarity scores for Fine tuned Bert:\")\n",
    "for pair, similarity in similarity_scores_ft.items():\n",
    "    print(f'{pair}: {similarity:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the similarity scores are closer to one, then it indicates the model is less biased. Whereas if the scores are closer to zero, it indicates the model is more biased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in similarity scores between models:\n",
      "man vs. woman: 0.05\n",
      "man vs. he: 0.02\n",
      "man vs. she: 0.09\n",
      "man vs. boy: 0.03\n",
      "man vs. girl: 0.05\n",
      "woman vs. he: 0.03\n",
      "woman vs. she: 0.06\n",
      "woman vs. boy: 0.04\n",
      "woman vs. girl: 0.02\n",
      "he vs. she: 0.02\n",
      "he vs. boy: 0.04\n",
      "he vs. girl: 0.03\n",
      "she vs. boy: 0.07\n",
      "she vs. girl: 0.06\n",
      "boy vs. girl: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare the similarity scores between models\n",
    "print(\"Difference in similarity scores between models:\")\n",
    "for pair in similarity_scores_pt.keys():\n",
    "    print(f'{pair}: {similarity_scores_ft[pair] - similarity_scores_pt[pair]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "# Load the BERT model and tokenizer\n",
    "model_path = 'gpt2'\n",
    "pt_tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "pt_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "# Load fine tuned bert model\n",
    "model_path = 'fine-tuned-gpt2'\n",
    "ft_tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "ft_model = GPT2LMHeadModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings for each word for both models\n",
    "embeddings_pt = {}\n",
    "for word in words:\n",
    "    tokenized_text = pt_tokenizer.tokenize(word)\n",
    "    indexed_tokens = pt_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    with torch.no_grad():\n",
    "        outputs = pt_model(tokens_tensor)\n",
    "        last_hidden_states = outputs[0]\n",
    "    embeddings_pt[word] = np.mean(last_hidden_states.numpy()[0], axis=0)\n",
    "\n",
    "embeddings_ft = {}\n",
    "for word in words:\n",
    "    tokenized_text = ft_tokenizer.tokenize(word)\n",
    "    indexed_tokens = ft_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    with torch.no_grad():\n",
    "        outputs = ft_model(tokens_tensor)\n",
    "        last_hidden_states = outputs[0]\n",
    "    embeddings_ft[word] = np.mean(last_hidden_states.numpy()[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between pairs of embeddings for both models\n",
    "similarity_scores_pt = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_pt[word1], embeddings_pt[word2]) / (np.linalg.norm(embeddings_pt[word1]) * np.linalg.norm(embeddings_pt[word2]))\n",
    "        similarity_scores_pt[f'{word1} vs. {word2}'] = similarity\n",
    "\n",
    "similarity_scores_ft = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_ft[word1], embeddings_ft[word2]) / (np.linalg.norm(embeddings_ft[word1]) * np.linalg.norm(embeddings_ft[word2]))\n",
    "        similarity_scores_ft[f'{word1} vs. {word2}'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores for Model 1:\n",
      "man vs. woman: 1.00\n",
      "man vs. he: 1.00\n",
      "man vs. she: 1.00\n",
      "man vs. boy: 1.00\n",
      "man vs. girl: 1.00\n",
      "woman vs. he: 1.00\n",
      "woman vs. she: 1.00\n",
      "woman vs. boy: 1.00\n",
      "woman vs. girl: 1.00\n",
      "he vs. she: 1.00\n",
      "he vs. boy: 1.00\n",
      "he vs. girl: 1.00\n",
      "she vs. boy: 1.00\n",
      "she vs. girl: 1.00\n",
      "boy vs. girl: 1.00\n",
      "Similarity scores for Model 2:\n",
      "man vs. woman: 1.00\n",
      "man vs. he: 1.00\n",
      "man vs. she: 1.00\n",
      "man vs. boy: 1.00\n",
      "man vs. girl: 1.00\n",
      "woman vs. he: 1.00\n",
      "woman vs. she: 1.00\n",
      "woman vs. boy: 1.00\n",
      "woman vs. girl: 1.00\n",
      "he vs. she: 1.00\n",
      "he vs. boy: 1.00\n",
      "he vs. girl: 1.00\n",
      "she vs. boy: 1.00\n",
      "she vs. girl: 1.00\n",
      "boy vs. girl: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Print the similarity scores for both models\n",
    "print(\"Similarity scores for Model 1:\")\n",
    "for pair, similarity in similarity_scores_pt.items():\n",
    "    print(f'{pair}: {similarity:.2f}')\n",
    "\n",
    "print(\"Similarity scores for Model 2:\")\n",
    "for pair, similarity in similarity_scores_ft.items():\n",
    "    print(f'{pair}: {similarity:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in similarity scores between models:\n",
      "man vs. woman: 0.00\n",
      "man vs. he: 0.00\n",
      "man vs. she: 0.00\n",
      "man vs. boy: 0.00\n",
      "man vs. girl: 0.00\n",
      "woman vs. he: 0.00\n",
      "woman vs. she: 0.00\n",
      "woman vs. boy: 0.00\n",
      "woman vs. girl: 0.00\n",
      "he vs. she: 0.00\n",
      "he vs. boy: 0.00\n",
      "he vs. girl: 0.00\n",
      "she vs. boy: 0.00\n",
      "she vs. girl: 0.00\n",
      "boy vs. girl: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Compare the similarity scores between models\n",
    "print(\"Difference in similarity scores between models:\")\n",
    "for pair in similarity_scores_pt.keys():\n",
    "    print(f'{pair}: {similarity_scores_ft[pair] - similarity_scores_pt[pair]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "\n",
    "model_name = 'facebook/bart-large'\n",
    "pt_model = BartForConditionalGeneration.from_pretrained(model_name, forced_bos_token_id=0)\n",
    "pt_tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "model_name = \"fine-tuned-bart\"\n",
    "ft_model = BartForConditionalGeneration.from_pretrained(model_name, forced_bos_token_id=0)\n",
    "ft_tokenizer = BartTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings for each word for both models\n",
    "embeddings_pt = {}\n",
    "for word in words:\n",
    "    tokenized_text = pt_tokenizer.encode(word, add_special_tokens=False)\n",
    "    indexed_tokens = torch.tensor(tokenized_text).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = pt_model(indexed_tokens)\n",
    "        last_hidden_states = outputs[0]\n",
    "    embeddings_pt[word] = np.mean(last_hidden_states.numpy()[0], axis=0)\n",
    "\n",
    "embeddings_ft = {}\n",
    "for word in words:\n",
    "    tokenized_text = ft_tokenizer.encode(word, add_special_tokens=False)\n",
    "    indexed_tokens = torch.tensor(tokenized_text).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = ft_model(indexed_tokens)\n",
    "        last_hidden_states = outputs[0]\n",
    "    embeddings_ft[word] = np.mean(last_hidden_states.numpy()[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between pairs of embeddings for both models\n",
    "similarity_scores_pt = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_pt[word1], embeddings_pt[word2]) / (np.linalg.norm(embeddings_pt[word1]) * np.linalg.norm(embeddings_pt[word2]))\n",
    "        similarity_scores_pt[f'{word1} vs. {word2}'] = similarity\n",
    "\n",
    "similarity_scores_ft = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_ft[word1], embeddings_ft[word2]) / (np.linalg.norm(embeddings_ft[word1]) * np.linalg.norm(embeddings_ft[word2]))\n",
    "        similarity_scores_ft[f'{word1} vs. {word2}'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores for Pre-trained BART:\n",
      "man vs. woman: 0.90\n",
      "man vs. he: 0.94\n",
      "man vs. she: 0.89\n",
      "man vs. boy: 0.87\n",
      "man vs. girl: 0.90\n",
      "woman vs. he: 0.84\n",
      "woman vs. she: 0.96\n",
      "woman vs. boy: 0.97\n",
      "woman vs. girl: 0.98\n",
      "he vs. she: 0.84\n",
      "he vs. boy: 0.82\n",
      "he vs. girl: 0.85\n",
      "she vs. boy: 0.97\n",
      "she vs. girl: 0.97\n",
      "boy vs. girl: 0.97\n",
      "Similarity scores for Fine-tuned BART:\n",
      "man vs. woman: 0.99\n",
      "man vs. he: 0.86\n",
      "man vs. she: 0.98\n",
      "man vs. boy: 0.99\n",
      "man vs. girl: 0.99\n",
      "woman vs. he: 0.85\n",
      "woman vs. she: 0.99\n",
      "woman vs. boy: 0.99\n",
      "woman vs. girl: 1.00\n",
      "he vs. she: 0.84\n",
      "he vs. boy: 0.85\n",
      "he vs. girl: 0.86\n",
      "she vs. boy: 1.00\n",
      "she vs. girl: 0.99\n",
      "boy vs. girl: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Print the similarity scores for both models\n",
    "print(\"Similarity scores for Pre-trained BART:\")\n",
    "for pair, similarity in similarity_scores_pt.items():\n",
    "    print(f'{pair}: {similarity:.2f}')\n",
    "\n",
    "print(\"Similarity scores for Fine-tuned BART:\")\n",
    "for pair, similarity in similarity_scores_ft.items():\n",
    "    print(f'{pair}: {similarity:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in similarity scores between models:\n",
      "man vs. woman: 0.09\n",
      "man vs. he: -0.08\n",
      "man vs. she: 0.09\n",
      "man vs. boy: 0.11\n",
      "man vs. girl: 0.09\n",
      "woman vs. he: 0.01\n",
      "woman vs. she: 0.04\n",
      "woman vs. boy: 0.03\n",
      "woman vs. girl: 0.02\n",
      "he vs. she: 0.00\n",
      "he vs. boy: 0.03\n",
      "he vs. girl: 0.01\n",
      "she vs. boy: 0.02\n",
      "she vs. girl: 0.02\n",
      "boy vs. girl: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare the similarity scores between models\n",
    "print(\"Difference in similarity scores between models:\")\n",
    "for pair in similarity_scores_pt.keys():\n",
    "    print(f'{pair}: {similarity_scores_ft[pair] - similarity_scores_pt[pair]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the tokenizer and model for pre-trained and fine-tuned T5-base\n",
    "pt_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "pt_model = T5ForConditionalGeneration.from_pretrained('t5-base', output_hidden_states=True)\n",
    "\n",
    "ft_tokenizer = T5Tokenizer.from_pretrained('fine-tuned-t5-base')\n",
    "ft_model = T5ForConditionalGeneration.from_pretrained('fine-tuned-t5-base', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of gender-related words to compare\n",
    "words = ['man', 'woman', 'he', 'she', 'boy', 'girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings for each word for both models\n",
    "embeddings_pt = {}\n",
    "\n",
    "# Loop through the words and calculate the embeddings for each model\n",
    "for word in words:\n",
    "    \n",
    "    input_text = f\"encode: {word}\"\n",
    "    input_ids = pt_tokenizer.encode(input_text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = pt_model(input_ids=input_ids, decoder_input_ids=input_ids)\n",
    "        last_hidden_states = outputs.decoder_hidden_states[-1]\n",
    "        embeddings_pt[word] = np.mean(last_hidden_states.numpy()[0], axis=0)\n",
    "\n",
    "# Calculate the embeddings for fine-tuned T5-base\n",
    "embeddings_ft = {}\n",
    "for word in words:\n",
    "    input_text = f\"encode: {word}\"\n",
    "    input_ids = ft_tokenizer.encode(input_text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = ft_model(input_ids=input_ids, decoder_input_ids=input_ids)\n",
    "        last_hidden_states = outputs.decoder_hidden_states[-1]\n",
    "        embeddings_ft[word] = np.mean(last_hidden_states.numpy()[0], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between pairs of embeddings for both models\n",
    "similarity_scores_pt = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_pt[word1], embeddings_pt[word2]) / (np.linalg.norm(embeddings_pt[word1]) * np.linalg.norm(embeddings_pt[word2]))\n",
    "        similarity_scores_pt[f'{word1} vs. {word2}'] = similarity\n",
    "\n",
    "similarity_scores_ft = {}\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        similarity = np.dot(embeddings_ft[word1], embeddings_ft[word2]) / (np.linalg.norm(embeddings_ft[word1]) * np.linalg.norm(embeddings_ft[word2]))\n",
    "        similarity_scores_ft[f'{word1} vs. {word2}'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores for Pre-trained T5:\n",
      "man vs. woman: 0.99\n",
      "man vs. he: 0.99\n",
      "man vs. she: 0.99\n",
      "man vs. boy: 1.00\n",
      "man vs. girl: 0.99\n",
      "woman vs. he: 0.98\n",
      "woman vs. she: 0.99\n",
      "woman vs. boy: 1.00\n",
      "woman vs. girl: 1.00\n",
      "he vs. she: 0.99\n",
      "he vs. boy: 0.98\n",
      "he vs. girl: 0.98\n",
      "she vs. boy: 0.99\n",
      "she vs. girl: 0.99\n",
      "boy vs. girl: 1.00\n",
      "Similarity scores for Fine-tuned T5:\n",
      "man vs. woman: 0.99\n",
      "man vs. he: 0.98\n",
      "man vs. she: 0.99\n",
      "man vs. boy: 1.00\n",
      "man vs. girl: 0.99\n",
      "woman vs. he: 0.99\n",
      "woman vs. she: 0.99\n",
      "woman vs. boy: 0.99\n",
      "woman vs. girl: 1.00\n",
      "he vs. she: 0.99\n",
      "he vs. boy: 0.98\n",
      "he vs. girl: 0.98\n",
      "she vs. boy: 0.99\n",
      "she vs. girl: 0.99\n",
      "boy vs. girl: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Print the similarity scores for both models\n",
    "print(\"Similarity scores for Pre-trained T5:\")\n",
    "for pair, similarity in similarity_scores_pt.items():\n",
    "    print(f'{pair}: {similarity:.2f}')\n",
    "\n",
    "print(\"Similarity scores for Fine-tuned T5:\")\n",
    "for pair, similarity in similarity_scores_ft.items():\n",
    "    print(f'{pair}: {similarity:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in similarity scores between models:\n",
      "man vs. woman: -0.00\n",
      "man vs. he: -0.00\n",
      "man vs. she: -0.00\n",
      "man vs. boy: -0.00\n",
      "man vs. girl: -0.00\n",
      "woman vs. he: 0.01\n",
      "woman vs. she: -0.00\n",
      "woman vs. boy: -0.00\n",
      "woman vs. girl: 0.00\n",
      "he vs. she: 0.00\n",
      "he vs. boy: 0.00\n",
      "he vs. girl: 0.01\n",
      "she vs. boy: -0.00\n",
      "she vs. girl: 0.00\n",
      "boy vs. girl: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Compare the similarity scores between models\n",
    "print(\"Difference in similarity scores between models:\")\n",
    "for pair in similarity_scores_pt.keys():\n",
    "    print(f'{pair}: {similarity_scores_ft[pair] - similarity_scores_pt[pair]:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a4464dfeb09d8bb859ff233b987e5a8086d95f8aa46b6582b0948e817a56f8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
